<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>xAI and Grok's Controversy - Rayan's Blog</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <h1>Rayan's Blog</h1>
        <nav>
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="#">About</a></li>
                <li><a href="#">Contact</a></li>
            </ul>
        </nav>
    </header>

    <div class="container">
        <main>
            <article class="post-content">
                <img src="https://techcrunch.com/wp-content/uploads/2023/11/xAI-Grok-GettyImages-1765893916.jpeg?resize=2048,1365" alt="xAI Grok Controversy" class="post-image">
                <h2>xAI blames Grok's obsession with white genocide on an 'unauthorized modification'</h2>
                <p class="post-meta">Posted on May 16, 2024 | Technology</p>
                
                <p>xAI blamed an "unauthorized modification" for a bug in its AI-powered Grok chatbot that caused Grok to repeatedly refer to "white genocide in South Africa" when invoked in certain contexts on X.</p>

                <p>On Wednesday, Grok began replying to dozens of posts on X with information about white genocide in South Africa, even in response to unrelated subjects. The strange replies stemmed from the X account for Grok, which responds to users with AI-generated posts whenever a person tags "@grok."</p>

                <h3>The Incident</h3>
                <p>According to a post Thursday from xAI's official X account, a change was made Wednesday morning to the Grok bot's system prompt — the high-level instructions that guide the bot's behavior — that directed Grok to provide a "specific response" on a "political topic." xAI says that the tweak "violated [its] internal policies and core values," and that the company has "conducted a thorough investigation."</p>

                <blockquote>
                    We want to update you on an incident that happened with our Grok response bot on X yesterday.<br><br>
                    What happened:<br>
                    On May 14 at approximately 3:15 AM PST, an unauthorized modification was made to the Grok response bot's prompt on X. This change, which directed Grok to provide a…<br><br>
                    — xAI (@xai) May 16, 2025
                </blockquote>

                <h3>Previous Incidents</h3>
                <p>It's the second time xAI has publicly acknowledged an unauthorized change to Grok's code caused the AI to respond in controversial ways.</p>

                <p>In February, Grok briefly censored unflattering mentions of Donald Trump and Elon Musk, the billionaire founder of xAI and owner of X. Igor Babuschkin, an xAI engineering lead, said that Grok had been instructed by a rogue employee to ignore sources that mentioned Musk or Trump spreading misinformation, and that xAI reverted the change as soon as users began pointing it out.</p>

                <h3>Future Measures</h3>
                <p>xAI said on Thursday that it's going to make several changes to prevent similar incidents from occurring in the future:</p>
                <ul>
                    <li>Publishing Grok's system prompts on GitHub</li>
                    <li>Maintaining a changelog</li>
                    <li>Implementing additional checks and measures</li>
                    <li>Establishing a 24/7 monitoring team</li>
                </ul>

                <h3>Safety Concerns</h3>
                <p>Despite Musk's frequent warnings of the dangers of AI gone unchecked, xAI has a poor AI safety track record. A recent report found that Grok would undress photos of women when asked. The chatbot can also be considerably more crass than AI like Google's Gemini and ChatGPT, cursing without much restraint to speak of.</p>

                <p>A study by SaferAI, a nonprofit aiming to improve the accountability of AI labs, found xAI ranks poorly on safety among its peers, owing to its "very weak" risk management practices. Earlier this month, xAI missed a self-imposed deadline to publish a finalized AI safety framework.</p>

                <a href="index.html" class="read-more">Back to Home</a>
            </article>
        </main>
    </div>
</body>
</html>